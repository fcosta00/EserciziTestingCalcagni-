} #metodi verificare bontà modello
#prova regressione curva
mtcars_reg2 <- lm(mpg ~ hp + I(hp^2), data = mtcars)
summary(mtcars_reg2)
plot(mtcars_reg2, which = 1)
x = seq(min(mtcars$hp),
max(mtcars$hp),
length = 1000)
yhat = predict(mtcars_reg2, newdata = data.frame('hp'= x))
plot(mpg ~ hp, data = mtcars)
lines(x, yhat, col=2)
#es1
summary(mtcars)
plot(mpg ~ wt, data = mtcars)
mpgwt_reg <- lm(mpg  ~ wt, data = mtcars)
summary(mpgwt_reg)
plot(mpg  ~ wt, data = mtcars)
abline(mpgwt_reg$coefficients, col = "red")
plot(mpgwt_reg, which=1)
mpgwt_reg2 <- lm(mpg  ~ wt + I(wt^2), data = mtcars)
summary(mpgwt_reg2)
plot(mpgwt_reg2, which=1)
x = seq(min(mtcars$wt),
max(mtcars$wt),
length = 1000)
yhat = predict(mpgwt_reg2, newdata = data.frame('wt'= x))
plot(mpg ~ wt, data = mtcars)
lines(x, yhat, col=2)
#es regrex multipla
multi_reg <- lm(mpg  ~ wt + hp, data = mtcars)
summary(multi_reg)
#prova reg multipla sensata
multi_reg_pro <- lm(mpg  ~ ., data = mtcars)
multi_reg_pro <- lm(mpg  ~ wt * am * hp, data = mtcars)
summary(multi_reg_pro)
plot(mpg  ~ am, data= mtcars )
multi_reg <- lm(mpg  ~ wt + am + hp, data = mtcars)
summary(multi_reg)
} # https://thefreolo.github.io/book/regressione.html#regressione-multipla
# Esercizi e prove personali non presenti a lezione
{
plot(mpg ~ hp, data = mtcars)
mtcars_reg <- lm(mpg ~ hp, data = mtcars)
summary(mtcars_reg)
par(mfrow = c(3,1), mar = c(2,2,1,1)) #tre grafici in fila
{
# Retta di regressione
plot(mpg ~ hp, data = mtcars)
abline(mtcars_reg$coefficients, col = "red")
# Pattern nei residui
plot(mtcars_reg$residuals, main = "Residui")
# Distribuzione in quantili
qqnorm(mtcars_reg$residuals)
qqline(mtcars_reg$residuals)
plot(mtcars_reg, which = 1)
} #metodi verificare bontà modello
#prova regressione curva
mtcars_reg2 <- lm(mpg ~ hp + I(hp^2), data = mtcars)
summary(mtcars_reg2)
plot(mtcars_reg2, which = 1)
x = seq(min(mtcars$hp),
max(mtcars$hp),
length = 1000)
yhat = predict(mtcars_reg2, newdata = data.frame('hp'= x))
plot(mpg ~ hp, data = mtcars)
lines(x, yhat, col=2)
#es1
summary(mtcars)
plot(mpg ~ wt, data = mtcars)
mpgwt_reg <- lm(mpg  ~ wt, data = mtcars)
summary(mpgwt_reg)
plot(mpg  ~ wt, data = mtcars)
abline(mpgwt_reg$coefficients, col = "red")
plot(mpgwt_reg, which=1)
mpgwt_reg2 <- lm(mpg  ~ wt + I(wt^2), data = mtcars)
summary(mpgwt_reg2)
plot(mpgwt_reg2, which=1)
x = seq(min(mtcars$wt),
max(mtcars$wt),
length = 1000)
yhat = predict(mpgwt_reg2, newdata = data.frame('wt'= x))
plot(mpg ~ wt, data = mtcars)
lines(x, yhat, col=2)
#es regrex multipla
multi_reg <- lm(mpg  ~ wt + hp, data = mtcars)
summary(multi_reg)
#prova reg multipla sensata
multi_reg_pro <- lm(mpg  ~ ., data = mtcars)
multi_reg_pro <- lm(mpg  ~ wt * am * hp, data = mtcars)
summary(multi_reg_pro)
plot(mpg  ~ am, data= mtcars )
multi_reg <- lm(mpg  ~ wt + am + hp, data = mtcars)
summary(multi_reg)
} # https://thefreolo.github.io/book/regressione.html#regressione-multipla
# E S E R C I Z I O   1
{
summary(iris)
#stesso identi grafici, x(ascisse) -> Sepal.Length, y(ordinate) -> Petal.Width,
plot( iris$Sepal.Length, iris$Petal.Width )
plot( Petal.Width ~ Sepal.Length , data = iris)
#coloro il grafico in base alla specie
plot( iris$Sepal.Length, iris$Petal.Width, col = iris$Species )
plot( iris$Sepal.Length, iris$Petal.Width, pch = 20, col = c('red', 'blue', 'green')[iris$Species])
#la specie sembra essere indicativa in quanto nei due cluster le specie non sono mescolate ma son ben divise (nel cluster 1 è presente solo una specie)
# Modello senza Species
modNoSpecies = lm(Petal.Width ~ Sepal.Length, data=iris)
summary(modNoSpecies)
# Modello con Species
modNoInt = lm(Petal.Width ~ Sepal.Length + Species, data=iris)
summary(modNoInt)
# Modello con interazione Sepal.Length e Species (equivalente a dire Sepal.Length*Species, coefficiente angolare specifico)
modInt = lm(Petal.Width ~ Sepal.Length + Species + Sepal.Length:Species, data=iris)
summary(modInt)
library(sjPlot)
plot_model(modNoSpecies, type="pred", terms=c("Sepal.Length"), ci.lvl = NA)
plot_model(modNoInt, type="pred", terms=c("Sepal.Length", "Species"), ci.lvl = NA)
plot_model(modInt, type="pred", terms=c("Sepal.Length", "Species"), ci.lvl = NA)
#controllo se il modello di interazione è significativo rispetto a quello senza interazione
anova(modNoInt, modInt)
#valore del test F molto alto, accetto per cui l'ipotesi H0, il modello con interazione non è significativamente differente
anova(modInt) #test che mostra la devianza dovuta a ogni regressore inserito
}
# E S E R C I Z I O   2
{
library(MASS)
#funzioni per capire la struttura del database che stiamo analizzando
summary(anorexia)
head(anorexia)
#converto il peso da libbre a kg
anorexia$Prewt <- anorexia$Prewt*0.4535
anorexia$Postwt <- anorexia$Postwt*0.4535
#grafico per il confronto delle terapie pre e post
boxplot(anorexia$Prewt[anorexia$Treat == 'Cont'], anorexia$Postwt[anorexia$Treat == 'Cont'],
anorexia$Prewt[anorexia$Treat == 'CBT'], anorexia$Postwt[anorexia$Treat == 'CBT'],
anorexia$Prewt[anorexia$Treat == 'FT'], anorexia$Postwt[anorexia$Treat == 'FT'],
names = c("Cont Pre","Cont Post","CBT Pre", 'CBT Post', 'FT Pre', 'FT Post'),
col = c('cyan4', 'cyan3', 'coral4', 'coral3', 'darkolivegreen4', 'darkolivegreen3'),
ylab = 'Weigth')
#grafico per il confronto delle terapie con delta post pre
boxplot(Postwt-Prewt ~ Treat, data = anorexia,
col = c('coral3', 'cyan3', 'darkolivegreen3'),
ylab = 'Weigth')
mod_interazione <- lm(Postwt ~ Prewt, data = anorexia[anorexia$Treat == 'FT',])
plot(Postwt ~ Prewt, data = anorexia[anorexia$Treat == 'FT',])
anorexiere = anorexia
anorexia$Treat = relevel(anorexia$Treat, ref = "Cont")
mod = lm(Postwt-Prewt ~ 0 + Treat, data = anorexia)
mod = lm(Postwt-Prewt ~ Treat, data = anorexia)
summary(mod)
anorexiere$Treat <- relevel(anorexiere$Treat, "Cont")
mod <- lm(Postwt ~ Prewt + Treat + Prewt:Treat, data = anorexiere)
plot_model(mod, type="pred", terms=c("Prewt", "Treat"))
modCont <- lm(Postwt-Prewt ~ Prewt + Treat + Prewt:Treat, data = anorexia)
mod <- lm(Postwt-Prewt ~ Treat, data = anorexia)
modCont <- lm(Postwt-Prewt ~ Treat, data = anorexia[anorexia$Treat == 'Cont',])
summary(mod)
plot( iris$Sepal.Length, iris$Petal.Width )
plot( Postwt-Prewt ~ Treat , data = anorexia)
plot_model(mod, type="pred", terms=c("Treat"), ci.lvl = NA)
anova(modCont)
boxplot(Postwt-Prewt ~ Treat, data = anorexia)
}
library('corrplot')
install.packages("qgraph")
install.packages("clusterGeneration")
install.packages("psych")
install.packages("mvtnorm")
install.packages("lavaan")
install.packages("corrplot")
install.packages("ggraph")
#######################################################
### Testing psicologico (PSP6075525)
### A.A. 2022/2023
### prof. Antonio Calcagnì (antonio.calcagni@unipd.it)
#######################################################
## CONTENUTO DEL CODICE ##################################
# (A) Sintassi di lavaan: modello e stime
# (B) Sintassi lavaan: valutazione del modello
##########################################################
# Inizializzazione ambiente di lavoro -------------------------------------
rm(list=ls()); graphics.off()
setwd("~/MEGA/Lavoro_sync/Didattica/2022_2023/testing_psicologico/")
install.packages("lavaanPlot")
load("C:/Users/franc/Downloads/Datasets-20221124/covariance_wisc.Rda")
source('"C:\Users\franc\Downloads\Utilities-20221124\plot_lavaan_model.R"')
source("C:\Users\franc\Downloads\Utilities-20221124\plot_lavaan_model.R")
# E s e r c i z i o   2
{
library(datasets)
str(attitude)
summary(attitude)
att2 <- attitude[,2:7] #prendo solo le colonne da 2 a 7, escludo per cui la prima variabile oddervata
# 1° punto
describe(att2)
# 2° punto
source('Utilities-20221124/split_half.R')
sh <- split_half(att2)
#??? quanto è valido?
# 3° punto
punteggi = matrix(NA, 30,3)
punteggi[,1] <- rowSums(att2)
mediaGrezzo <- mean(punteggi[,1])
punteggi[,2] <- punteggi[,1]*sh + (1-sh)*mediaGrezzo
# 4° punto
library(psych)
summary(alpha(att2))
ac <- 0.81
punteggi[,3] <- punteggi[,1]*ac + (1-ac)*mediaGrezzo
colnames(punteggi) <- c('grezzo', 'split_half', 'cronbach')
# 5° punto
plot(density(punteggi[,1]), main = 'Grezzo', xlim=c(150,550))
plot(density(punteggi[,2]), main = 'Split Half', xlim=c(150,550))
plot(density(punteggi[,3]), main = 'Cronbach', xlim=c(150,550))
describe(punteggi)
# 6° punto
pairs(att2)
heatmap(cov(att2), scale='none')
library(corrplot)
corrplot(cor(att2))
#commento boh????????
}
library(psych)
# E s e r c i z i o   3
{
load('Datasets-20221124/mach/mach.Rdata')
# 1° punto
str(datax)
summary(datax)  # insieme di punteggi categoriali da -8 a 8 su 20 item divisi per nazione
# 2° punto
dataxITA <- datax[datax$country == "IT",]
dataxITA <- dataxITA[,1:20]
# 3° punto
library(lavaan)
heatmap(cor(dataxITA), scale = 'none')
mod_uni = ' lat1=~ Q6A + Q10A + Q7A + Q3A + Q9A + Q16A \n '
mod_uni_fit_UVI = cfa( model = mod_uni, data = dataxITA, std.lv = TRUE)
summary(mod_uni_fit_UVI, fit.measures = TRUE)
library(semPlot)
x11();semPaths(object = mod_uni_fit_UVI, what="model", whatLabels = "std")
# 4° punto
#* L'adattamento del modello sembra buono, i valori di lambda stimati oscillano tra i 0.44 e i 0.67
#* il RMSEA è molto basso 0.028 e inferiore al p-value < 0.05
# 5° punto
source('Utilities-20221124/reliability_semTools.R')
reliability(mod_uni_fit_UVI)
# 6° punto
mod_plu = ' lat1=~ Q6A + Q7A \n
lat2=~ Q4A + Q11A \n
lat3=~ Q1A + Q2A '
mod_plu_fit_UVI = cfa( model = mod_plu, data = dataxITA, std.lv = TRUE)
summary(mod_plu_fit_UVI, fit.measures = TRUE)
x11();semPaths(object = mod_plu_fit_UVI, what="model", whatLabels = "std")
# 7° piano
cfa_fits = matrix(NA, 2,6)  #creo mattice nuovo
cfa_fits[1,] = fitmeasures(object = mod_uni_fit_UVI,
fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar'))
cfa_fits[2,] = fitmeasures(object = mod_plu_fit_UVI,
fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar'))
colnames(cfa_fits) = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')
rownames(cfa_fits) = c('uni', 'plu')
cfa_fits
reliability(mod_plu_fit_UVI)
}
dataex9 <- read.csv("C:/Users/franc/OneDrive - Università degli Studi di Padova/Università-PC-senzaMilza/3° Anno/Testing/EserciziTestingCalcagni-/Datasets-20221124/dataex9.csv")
View(dataex9)
setwd("C:/Users/franc/OneDrive - Università degli Studi di Padova/Università-PC-senzaMilza/3° Anno/Testing/EserciziTestingCalcagni-")
#1
source('Utilities-20221124/utilities.R')
library(lavaan)
library(semPlot)
library(mvtnorm)
datax <- dataex9
datax <- datax[, 2:8]
str(datax)
head(datax)
summary(datax)
#analisi esplorativa
m_cor <- cor( datax[,1:6], method = 'pearson') # method='spearman' se ci sono variabili categoriali (default o pearson altrimenti)
D <- dist(m_cor, method = 'euclidean')
hc <- hclust(d = D, method = 'ward.D2')
plot(hc)
mod_2 <-hclust2lavaan(tree = hc, ngroups = 2)
mod_1 <- "eta1 =~ y1+y2+y3+y4+y5+y6"
mod_2 <- "eta1 =~ y1+y2+y3+y4 \n eta2 =~ y5+y6"
mod_3 <- "eta1 =~ y1+y2+y3+y4 \n eta2 =~ y5+y6 \n etabi =~ y1+y2+y3+y4+y5+y6 \n etabi ~~ 0*eta1 \n etabi ~~ 0*eta2"
mod_1_fit <- cfa( model = mod_1, data = datax[,1:6]) #varibili continue
lavaan_checkConvergence(mod_1_fit)
round(fitmeasures(object = mod_1_fit, fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')), 3)
summary(mod_1_fit, fit.measures = TRUE, standardized=TRUE )
p = NCOL(datax[,1:6])
mod_2_fit <- cfa( model = mod_2, data = datax) #varibili continue
lavaan_checkConvergence(mod_2_fit)
round(fitmeasures(object = mod_2_fit, fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')), 3)
summary(mod_2_fit, fit.measures = TRUE, standardized=TRUE )
p = NCOL(datax[,1:6])
mod_3_fit <- cfa( model = mod_3, data = datax) #varibili continue
lavaan_checkConvergence(mod_3_fit)
mod_4 <- "eta1 =~ y1+y2+y3+y4 \n eta2 =~ y5+y6 \n eta3 =~ eta1 + eta2"
mod_4_fit <- cfa( model = mod_4, data = datax[,1:6]) #varibili continue
lavaan_checkConvergence(mod_4_fit)
round(fitmeasures(object = mod_4_fit, fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')), 3)
summary(mod_4_fit, fit.measures = TRUE, standardized=TRUE )
p = NCOL(datax[,1:6])
100*(12/(p*(p+1)/2))
reliability(mod_1_fit,return.total = TRUE)
reliability(mod_2_fit,return.total = TRUE)
bfi.eta = lavPredict(object = mod_2_fit,type = "lv",method = "regression")
reliability(mod_2_fit,return.total = TRUE)
pr_ftt = lavPredict(object = mod_2_fit,type = "lv",method = "regression")
matrix2 = inspect(object = mod_2_fit, what="std.all")
zeta <- (pr_ftt %*% matrix2$psi) %*% c(1,1)
hist(bfi.eta[,1],main="eta1",ylab="",xlab="")
hist(bfi.eta[,2],main="eta2",ylab="",xlab="")
hist(fg[,1],main="eta1",ylab="",xlab="")
hist(fg[,2],main="eta2",ylab="",xlab="")
hist(bfi.eta[,1],main="eta1",ylab="",xlab="")
hist(bfi.eta[,2],main="eta2",ylab="",xlab="")
View(zeta)
mod_1_conf = cfa(model = mod_1, data = datax,group = "z")
mod_1_weak = cfa(model = mod_1, data = datax,group = "z",group.equal="loadings")
anova(mod_1_conf,mod_1_weak)
mod_1_strong = cfa(model = mod_1, data = datax,group = "group",group.equal=c("loadings","intercepts"))
mod_1_strong = cfa(model = mod_1, data = datax,group = "z",group.equal=c("loadings","intercepts"))
anova(mod_1_weak,mod_1_strong)
mod_1_strict = cfa(model = mod_1, data = datax,group = "group",group.equal=c("loadings","intercepts","residuals"))
mod_1_strict = cfa(model = mod_1, data = datax,group = "z",group.equal=c("loadings","intercepts","residuals"))
anova(mod_1_strong,mod_1_strict)
source('Utilities-20221124/utilities.R')
library(lavaan)
library(semPlot)
library(mvtnorm)
load('Datasets-20221124/mimic.Rdata')
datax <- mimic
datax$z <- z
source('Datasets-20221124/finance.Rdata')
library(lavaan)
library(semPlot)
library(mvtnorm)
load('data_exam.Rdata')
str(datax)
source('Utilities-20221124/utilities.R')
library(lavaan)
library(semPlot)
library(mvtnorm)
load('Datasets-20221124/finance.Rdata')
datax <- financce
str(datax)
head(datax)
summary(datax)
datax <- finance
str(datax)
head(datax)
summary(datax)
for(j in 2:NCOL(datax)-1){
datax[,j] = factor(datax[,j],ordered = TRUE)
}
datax$gender <- as.factor(datax$gender)
datax$gender <- as.factor(datax$gendePPGENDER)
str(datax)
datax[1]
datax <- finance
str(datax)
head(datax)
summary(datax)
for(j in 2:NCOL(datax)-1){
datax[,j] = factor(datax[,j],ordered = TRUE)
}
str(datax)
datax <- finance
datax[,2] = factor(datax[,2],ordered = TRUE)
str(datax)
for(j in 2:(NCOL(datax)-1)){
datax[,j] = factor(datax[,j],ordered = TRUE)
}
str(datax)
datax$gender <- as.factor(datax$PPGENDER)
str(datax)
datax <- finance
str(datax)
head(datax)
summary(datax)
datax$PPGENDER <- as.factor(datax$PPGENDER)
str(datax)
for(j in 2:(NCOL(datax)-1)){
datax[,j] = factor(datax[,j],ordered = TRUE)
}
str(datax)
datax <- split_dataset(data = datax, prop = 0.3)
d_a <- datax$A
d_b <- datax$B
# 2
m_cor <- cor( d_a, method = 'spearman') # method='spearman' se ci sono variabili categoriali (default o pearson altrimenti)
D <- dist(m_cor, method = 'euclidean')
hc <- hclust(d = D, method = 'ward.D2')
# 2
m_cor <- cor( d_a[,2:11], method = 'spearman') # method='spearman' se ci sono variabili categoriali (default o pearson altrimenti)
head(d_a[,2:11])
datax <- finance
str(datax)
head(datax)
summary(datax)
datax$PPGENDER <- as.factor(datax$PPGENDER)
# 1
datax <- split_dataset(data = datax, prop = 0.3)
d_a <- datax$A
d_b <- datax$B
# 2
m_cor <- cor( d_a[,2:11], method = 'spearman') # method='spearman' se ci sono variabili categoriali (default o pearson altrimenti)
# 2
m_cor <- cor( d_a[,2:11], method = 'spearman') # method='spearman' se ci sono variabili categoriali (default o pearson altrimenti)
D <- dist(m_cor, method = 'euclidean')
hc <- hclust(d = D, method = 'ward.D2')
plot(hc)
mod_1 <-hclust2lavaan(tree = hc, ngroups = 2)
mod_1
#3
#lo eseguo dopo in quanto mi serve numerico per la matrice di correlazione
for(j in 2:(NCOL(d_b)-1)){
d_b[,j] = factor(d_b[,j],ordered = TRUE)
}
str(d_a)
str(d_b)
d_b$PPGENDER <- as.character(d_b$PPGENDER)
mod_1_conf = cfa(model = mod_1, data = datax,group = "group")
mod_1_conf = cfa(model = mod_1, data = d_b,group = "PPGENDER")
mod_1_conf = cfa( model = mod_1, data = d_b[2:12], ordered=colnames(d_b[,2:11]), estimator="DWLS", group = "PPGENDER")
d_b <- d_b[,2:12]
head(d_b)
str(d_b)
mod_1_conf = cfa( model = mod_1, data = d_b, ordered=colnames(d_b[,1:10]), estimator="DWLS", group = "PPGENDER")
d_b
mod_1_conf = cfa( model = mod_1, data = d_b, ordered=colnames(d_b[,1:10]), estimator="DWLS")
mod_1_fit = cfa( model = mod_1, data = d_b, ordered=colnames(d_b[,1:10]), estimator="DWLS")
lavaan_checkConvergence(mod_1_fit)
round(fitmeasures(object = mod_1_fit, fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')), 3)
summary(mod_1_fit, fit.measures = TRUE, standardized=TRUE )
mod_1_conf = cfa(model = mod_1, data = d_b, ordered=colnames(d_b[,1:10]), estimator="DWLS", group = 'PPGENDER')
mod_1_fit = cfa( model = mod_1, data = d_b, ordered=colnames(d_b)[1:10], estimator="DWLS")
lavaan_checkConvergence(mod_1_fit)
round(fitmeasures(object = mod_1_fit, fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')), 3)
summary(mod_1_fit, fit.measures = TRUE, standardized=TRUE )
mod_1_conf = cfa(model = mod_1, data = d_b, ordered=colnames(d_b)[1:10], estimator="DWLS", group = 'PPGENDER')
mod_conf = cfa(model = mod, data = d_b, order = colnames(d_b)[1:10], estimator = 'DWLS', group = 'PPGENDER')
mod_conf = cfa(model = mod_1, data = d_b, order = colnames(d_b)[1:10], estimator = 'DWLS', group = 'PPGENDER')
d_b
# 1
datax <- split_dataset(data = datax, prop = 0.3, seed = 8219291)
d_a <- datax$A
d_b <- datax$B
source('Utilities-20221124/utilities.R')
library(lavaan)
library(semPlot)
library(mvtnorm)
load('Datasets-20221124/finance.Rdata')
datax <- finance
str(datax)
head(datax)
summary(datax)
datax$PPGENDER <- as.factor(datax$PPGENDER)
# 1
datax <- split_dataset(data = datax, prop = 0.3, seed = 8219291)
d_a <- datax$A
d_b <- datax$B
# 2
m_cor <- cor( d_a[,2:11], method = 'spearman') # method='spearman' se ci sono variabili categoriali (default o pearson altrimenti)
D <- dist(m_cor, method = 'euclidean')
hc <- hclust(d = D, method = 'ward.D2')
plot(hc)
cutree(tree = hc, k = 2)
mod_1 <-hclust2lavaan(tree = hc, ngroups = 2)
#3
#lo eseguo dopo in quanto mi serve numerico per la matrice di correlazione
for(j in 2:(NCOL(d_b)-1)){
d_b[,j] = factor(d_b[,j],ordered = TRUE)
}
d_b$PPGENDER <- as.character(d_b$PPGENDER)
d_b <- d_b[,2:12]
mod_1_fit = cfa( model = mod_1, data = d_b, ordered=colnames(d_b)[1:10], estimator="DWLS")
lavaan_checkConvergence(mod_1_fit)
round(fitmeasures(object = mod_1_fit, fit.measures = c('RMSEA', 'CFI', 'AIC', 'chisq', 'df', 'npar')), 3)
summary(mod_1_fit, fit.measures = TRUE, standardized=TRUE )
mod_1_conf = cfa(model = mod_1, data = d_b, ordered=colnames(d_b)[1:10], estimator="DWLS", group = 'PPGENDER')
mod_conf = cfa(model = mod_1, data = d_b, order = colnames(d_b)[1:10], estimator = 'DWLS', group = 'PPGENDER')
mod_1_weak = cfa(model = mod_1, data = datax,group = "group",group.equal="loadings")
anova(mod_1_conf,mod_1_weak)
mod_1_conf = cfa(model = mod_1, data = d_b, order = colnames(d_b)[1:10], estimator = 'DWLS', group = 'PPGENDER')
mod_1_weak = cfa(model = mod_1, data = datax,group = "group",group.equal="loadings")
mod_1_weak = cfa(model = mod_1, data = d_b, order = colnames(d_b)[1:10], estimator = 'DWLS', group = 'PPGENDER',group.equal="loadings")
anova(mod_1_conf,mod_1_weak)
evaluate_partial_invariance(fitted_model = mod_1_weak, type = "metric")
#Cerchiamo lambda che sono presenti in entrambi gruppi con alto indice di modifica
# eta2 =~ FWB1_5 e eta2 =~ FWB1_3 e eta2 =~ FWB2_1 candidati parametri da liberare
#Più parametri perché dobbiamo modificare tanto il nostro pvalue
mod_1_weak_parz = cfa(model = mod_1, data = d_b, ordered = colnames(d_b),
estimator = "DWLS", group = "group", group.equal = c("loadings"),
group.partial = c("eta2 =~ FWB1_5","eta2 =~ FWB1_3","eta2 =~ FWB2_1"))
#Cerchiamo lambda che sono presenti in entrambi gruppi con alto indice di modifica
# eta2 =~ FWB1_5 e eta2 =~ FWB1_3 e eta2 =~ FWB2_1 candidati parametri da liberare
#Più parametri perché dobbiamo modificare tanto il nostro pvalue
mod_1_weak_parz = cfa(model = mod_1, data = d_b, ordered = colnames(d_b),
estimator = "DWLS", group = "PPGENDER", group.equal = c("loadings"),
group.partial = c("eta2 =~ FWB1_5","eta2 =~ FWB1_3","eta2 =~ FWB2_1"))
anova(mod_1_weak_parz, mod_1_conf)
mod_1_strong_parz = cfa(model = mod_1, data = d_b, ordered = colnames(d_b),
estimator = "DWLS", group = "PPGENDER", group.equal = c("loadings",'intercepts'),
group.partial = c("eta2 =~ FWB1_5","eta2 =~ FWB1_3","eta2 =~ FWB2_1"))
anova(mod_1_weak,mod_1_strong)
anova(mod_1_weak_parz,mod_1_strong_parz)
anova(mod_1_weak_parz, mod_1_conf)
summary_table(fitted_model = mod_1_strong, type_summary = 'intercept', standardized = TRUE)
summary_table(fitted_model = mod_1_strong, type_summary = 'intercept', standardized = TRUE)
summary_table(fitted_model = mod_1_strong_parz, type_summary = 'intercept', standardized = TRUE)
